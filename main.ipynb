{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Northeastern SMILE Lab - Recognizing Faces in the Wild**\n",
    "\n",
    "## Background\n",
    "\n",
    "The SMILE Lab at Northeastern focuses on the frontier research of applied machine learning, social media analytics, human-computer interaction, and high-level image and video understanding. Their research is driven by the explosion of diverse multimedia from the Internet, including both personal and publicly available photos and videos. They start by treating fundamental theory from learning algorithms as the soul of machine intelligence and arm it with visual perception.\n",
    "\n",
    "Northeastern University has been developing an automatic kinship classifier since 2010. However, the widespread adoption of this technology has been hindered by two primary factors:\n",
    "\n",
    "- Data Limitations: Existing image databases for kinship recognition are insufficient in size and diversity to accurately represent global familial relationships.\n",
    "\n",
    "- Model Complexity: The complex interplay of genetic and environmental factors influencing facial features necessitates a more advanced model than traditional computer vision algorithms, which are typically designed for higher-level tasks like facial recognition or object classification.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Using the provided competition data, the following model predicts the probability of two individuals being related (1) based solely on a pair of facial images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preliminaries**: Install the following Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If they are not already installed, this cell installs the modules used in this solution.\n",
    "%pip install collections\n",
    "%pip install glob\n",
    "%pip install kaggle\n",
    "%pip install matplotlib\n",
    "%pip install os\n",
    "%pip install pandas\n",
    "%pip install sklearn\n",
    "%pip install torch\n",
    "%pip install torch.nn\n",
    "%pip install torch.optim\n",
    "%pip install zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1**: Download the official Kaggle competition (FIW) data.\n",
    "\n",
    "***Before executing the following cell***, please review section 7 of the rules: https://www.kaggle.com/competitions/recognizing-faces-in-the-wild/rules#7-competition-data. \n",
    "\n",
    "Note that all usages of FIW data should cite the following papers:\n",
    "\n",
    "*Joseph P Robinson, Ming Shao, Hongfu Liu, Yue Wu, Timothy Gillis, and Yun Fu. \"Visual Kinship Recognition of Families In the Wild\" IEEE TPAMI Special Edition: Computational Face (2018).\n",
    "Joseph P Robinson, Ming Shao, Handong Zhao, Yue Wu, Timothy Gillis, Yun Fu. \"Recognizing Families In the Wild (RFIW): Data Challenge Workshop in conjunction with ACM MM 2017,\" ACM Multimedia Conference: Workshop on RFIW (2017).\n",
    "Shuyang Wang, Joseph P Robinson, and Yun Fu. “Kinship Verification on Families in the Wild with Marginalized Denoising Metric Learning,” in IEEE Automatic Face and Gesture Recognition (2017).\n",
    "Joseph P Robinson, Ming Shao, Yue Wu, and Yun Fu. “Families In the Wild (FIW): large-scale kinship image database and benchmarks.\" in ACM on Multimedia Conference (2016).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = '_provided-data' # Intermediate directories are excluded recursively via. .gitignore (i.e., '_*/').\n",
    "competition = 'recognizing-faces-in-the-wild' # Hosted here: https://www.kaggle.com/c/recognizing-faces-in-the-wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "print('Downloading ' + competition + ' provided data into ' + download_path)\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.competition_download_files(competition, path = download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def unzip(zip_path):\n",
    "    dest_dir = '_' + os.path.basename(zip_path)[:-4]\n",
    "    if (not os.path.exists(dest_dir)):\n",
    "        os.makedirs(dest_dir, exist_ok=True)\n",
    "        print('Decompressing ' + zip_path + ' into ' + dest_dir)\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(dest_dir)\n",
    "    print(dest_dir + '/')\n",
    "    print(os.listdir(dest_dir))\n",
    "    return dest_dir\n",
    "\n",
    "print('Decompressing ' + competition + ' provided data:')\n",
    "dataset_path = unzip(download_path + '/' + competition + '.zip')\n",
    "training_image_path = unzip(dataset_path + '/train-faces.zip')\n",
    "testing_image_path = unzip(dataset_path + '/test-faces.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Preprocess the image portion of the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# Create a dictionary to lookup image files for each member\n",
    "family_dict = defaultdict(list)\n",
    "for family in glob.glob(training_image_path + '*'):\n",
    "    for member in glob.glob(family + '/*'):\n",
    "        for image_path in glob.glob(member + '/*'):\n",
    "            member = member.split('\\\\')[-1]\n",
    "            image_path = image_path.split('\\\\')[-1]\n",
    "            family_dict[member].append(image_path)\n",
    "\n",
    "print('Here are the first few of the ' + str(len(family_dict.items())) + ' total families:')\n",
    "for key, value in list(family_dict.items())[:5]:\n",
    "    print(str(key) + ': ' + str(value) + ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4**: Preprocess (clean) the relational portion of the provided dataset.\n",
    "\n",
    "The _train_relationships.csv_ encodes (ground truth) kinship relations between pairs of people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "relations_csv_path = dataset_path + '/train_relationships.csv'\n",
    "print('Loading ' + relations_csv_path)\n",
    "relations_df = pandas.read_csv(relations_csv_path, delimiter=',', header='infer')\n",
    "relations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Remove invalid encodings\n",
    "To improve the training efficiency, the relations dataframe is groomed to be fully valid (each referenced family member has at least one images in train-faces\\...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "relations_csv_path = dataset_path + '/train_relationships.csv'\n",
    "print('Loading ' + relations_csv_path)\n",
    "relations_df = pandas.read_csv(relations_csv_path, delimiter=',', header='infer')\n",
    "\n",
    "# Remove entries which do not exist in the training set\n",
    "print('The original ground truth relations data contains ' + str(len(relations_df)) + ' entries.')\n",
    "print(relations_df)\n",
    "\n",
    "print('Checking for missing relation image data.')\n",
    "fam_keys = family_dict.keys()\n",
    "missing_relations_list = []\n",
    "for index, row in relations_df.iterrows():\n",
    "    split1 = row.p1.split('/')\n",
    "    split2 = row.p2.split('/')\n",
    "    p1fam = split1[0]\n",
    "    p2fam = split2[0]\n",
    "    if (p1fam not in fam_keys or p2fam not in fam_keys):\n",
    "        missing_relations_list.append(index)\n",
    "        continue\n",
    "    p1member = split1[1]\n",
    "    p2member = split2[1]\n",
    "    if (p1member not in family_dict[p1fam] or p2member not in family_dict[p2fam]):\n",
    "        missing_relations_list.append(index)\n",
    "        continue\n",
    "    images1 = os.listdir(training_image_path + '/' + p1fam + '/' + p1member)\n",
    "    images2 = os.listdir(training_image_path + '/' + p2fam + '/' + p2member)\n",
    "    if (len(images1) == 0 or len(images2) == 0):\n",
    "        missing_relations_list.append(index)\n",
    "        continue\n",
    "if (missing_relations_list.count):\n",
    "    relations_df = relations_df.drop(missing_relations_list)\n",
    "    print(str(len(missing_relations_list)) + ' entries were removed due to missing data.')\n",
    "    print(relations_df)\n",
    "else:\n",
    "    print('All relations were found to have valid image data.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Create a lookup function to return if members are related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This utility function to check if two members are related, regardless of the provided order.\n",
    "def isRelated(df, p1, p2):\n",
    "    return (df[(df['p1'] == p1) & (df['p2'] == p2)].shape[0] > 0) \\\n",
    "        or (df[(df['p1'] == p2) & (df['p2'] == p1)].shape[0] > 0)\n",
    "\n",
    "# Show a couple of true negatives and true positives\n",
    "print(isRelated(relations_df, 'bad', 'data'))              # False\n",
    "print(isRelated(relations_df, 'F0002/MID2', 'F0005/MID2')) # False\n",
    "print(isRelated(relations_df, 'F0998/MID6', 'F0998/MID3')) # True\n",
    "print(isRelated(relations_df, 'F0998/MID3', 'F0998/MID6')) # True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Build a list of ground truth members and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all of the members in the relations data\n",
    "members = []\n",
    "for member in relations_df.values:\n",
    "    if (member[0] not in members):\n",
    "        members.append(member[0])\n",
    "    if (member[0] not in members):\n",
    "        members.append(member[0])\n",
    "members.sort()\n",
    "print(str(len(members)) + ' total members in the training set:')\n",
    "print(members)\n",
    "\n",
    "# Create a list of the corresponding images\n",
    "image_set = []\n",
    "for member in members:\n",
    "    set = os.listdir(training_image_path + '/' + member)\n",
    "    if (len(set) > 0):\n",
    "        for image in set:\n",
    "            image_set.append(member + '/' + image)\n",
    "print(str(len(image_set)) + ' total images in the training set:')\n",
    "print(image_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Use a a portion of the images for training (training_images)...\n",
    "training_images = random.sample(image_set, int(len(image_set)               -100))\n",
    "print(str(len(training_images)) + ' images in training_images')\n",
    "training_images.sort()\n",
    "print('Showing the first three (sorted):')\n",
    "print(training_images[:3])\n",
    "print('Showing the first three (after shuffling):')\n",
    "random.shuffle(training_images)\n",
    "print(training_images[:3])\n",
    "\n",
    "# ...and the remaining for testing (test_images).\n",
    "test_images = [x for x in image_set if x not in training_images]\n",
    "print(str(len(test_images)) + ' images in test_images')\n",
    "print('Showing the first three (sorted):')\n",
    "print(test_images[:3])\n",
    "random.shuffle(test_images)\n",
    "print('Showing the first three (after shuffling):')\n",
    "print(test_images[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Test that at least one image exists for a random selection of the relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "SAMPLE_COUNT = 3\n",
    "samples = relations_df.sample(SAMPLE_COUNT)\n",
    "print(samples)\n",
    "\n",
    "f, ax = plt.subplots(SAMPLE_COUNT, 2)\n",
    "f.patch.set_alpha(0) # Transparent background\n",
    "for a in ax.flat:\n",
    "    a.axis('off')\n",
    "i = 0\n",
    "for member in samples.values:\n",
    "    img1 = training_image_path + '/' + member[0] + '/' \\\n",
    "        + choice(os.listdir(training_image_path + '/' + member[0]))\n",
    "    img2 = training_image_path + '/' + member[1] + '/'  \\\n",
    "        + choice(os.listdir(training_image_path + '/' + member[1]))\n",
    "    rgb1 = cv2.cvtColor(cv2.imread(img1), cv2.COLOR_BGR2RGB)\n",
    "    rgb2 = cv2.cvtColor(cv2.imread(img2), cv2.COLOR_BGR2RGB)\n",
    "    ax[i][0].imshow(rgb1, cmap = plt.cm.Spectral)\n",
    "    ax[i][1].imshow(rgb2, cmap = plt.cm.Spectral)  \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training process:\n",
    "\n",
    "1. Pass the first image of the image pair through the network.\n",
    "2. Pass the 2nd image of the image pair through the network.\n",
    "3. Calculate the loss using the results of the prior steps.\n",
    "4. Back propagate the loss to calculate the gradients.\n",
    "5. Update the weights using an optimizer (Adam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(64 * 12 * 12, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "\n",
    "# Define the contrastive loss function\n",
    "def contrastive_loss(output1, output2, label):\n",
    "    euclidean_distance = torch.sqrt(torch.sum((output1-output2)**2, dim=1, keepdim=True))\n",
    "    loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                  (label) * torch.pow(torch.clamp(2-euclidean_distance, min=0.0), 2))\n",
    "    return loss_contrastive\n",
    "\n",
    "# Create the Siamese network\n",
    "model = SiameseNetwork()\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "criterion = contrastive_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training loop\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (data1, data2, label) in enumerate(dataloader):\n",
    "        data1, data2, label = data1.to(device), data2.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output1, output2 = model(data1, data2)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * data1.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    print(f'Epoch Loss: {epoch_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "MODEL = False\n",
    "if (MODEL):\n",
    "    # Create a list of all of the image pairs in the test-faces data\n",
    "    test_pairs = list(itertools.combinations(os.listdir(testing_image_path), 2))\n",
    "else:\n",
    "    # For now, use a portion of the ground truth relations data for testing\n",
    "    test_pairs = list(itertools.combinations(test_images, 2))\n",
    "    \n",
    "    # Remove invalid pairs (same member)\n",
    "    invalid_pairs = []\n",
    "    i = 0\n",
    "    for pair in test_pairs:\n",
    "        person1fam_index = pair[0].find('/')\n",
    "        person2fam_index = pair[1].find('/')\n",
    "        person1 = pair[0][:pair[0].find('/', person1fam_index+1)]\n",
    "        person2 = pair[1][:pair[1].find('/', person2fam_index+1)]\n",
    "        if (person1 == person2):\n",
    "            invalid_pairs.append(i)\n",
    "        i = i + 1\n",
    "    test_pairs = [x for i, x in enumerate(test_pairs) if i not in invalid_pairs]\n",
    "    print(str(len(invalid_pairs)) + ' pairs of the same member were removed.')\n",
    "    \n",
    "print('There are ' + str(len(test_pairs)) + ' total pairs in the test set.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def predict_related(img1, img2):\n",
    "    likelihood = (path1[:path1.find('/')] == path2[:path2.find('/')])\n",
    "    return int(likelihood)*0.999\n",
    "    # TODO Once the model is trained, use it instead of the above placeholder\n",
    "    # TODO Preprocess the images\n",
    "    output1, output2 = model(img1, img2)\n",
    "    distance = torch.sqrt(torch.sum( (output1 - output2)**2, dim=1, keepdim = True ))\n",
    "    return 1-distance\n",
    "        \n",
    "results = []\n",
    "print(len(test_pairs))\n",
    "for pair in test_pairs:\n",
    "    person1fam_index = pair[0].find('/')\n",
    "    person2fam_index = pair[1].find('/')\n",
    "    person1 = pair[0][:pair[0].find('/', person1fam_index+1)]\n",
    "    person2 = pair[1][:pair[1].find('/', person2fam_index+1)]\n",
    "    results.append({'actual':int(isRelated(relations_df, person1, person2)),\n",
    "                    'prediction':float(predict_related(pair[0], pair[1]))})\n",
    "\n",
    "\n",
    "results_df = pandas.DataFrame(results)\n",
    "results_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step ?**: Evaluation\n",
    "Submissions are [evaluated](https://www.kaggle.com/competitions/recognizing-faces-in-the-wild/overview/evaluation) on area under the ROC curve between the predicted probability and the observed target. Not all pairs will be scored.\n",
    "\n",
    "**Submission File**\n",
    "\n",
    "For each img_pair in the test set, you must predict a probability for the is_related variable. The column img_pair describes the pair of images, i.e., abcdef-ghijkl means the pair of images abcdef.jpg and ghijkl.jpg.\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "img_pair,is_related\n",
    "X3Nk6Hfe5x-qcZrTXsfde,0.0\n",
    "X3Nk6Hfe5x-LD0pWDM8w_,0.0\n",
    "X3Nk6Hfe5x-PHwuDtHyGp,0.0\n",
    "X3Nk6Hfe5x-LO6lN_U4ot,0.0\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "def generate_roc_curve(data):\n",
    "  true_labels = [d['actual'] for d in data]\n",
    "  predicted_probs = [d['prediction'] for d in data]\n",
    "  fpr, tpr, _ = roc_curve(true_labels, predicted_probs)\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  plt.figure()\n",
    "  plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "  plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "  plt.legend(loc=\"lower right\")\n",
    "  return plt\n",
    "    \n",
    "generate_roc_curve(results).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "submission = [['img_pair', 'is_related']]\n",
    "for pair,result in zip(test_pairs, results):\n",
    "    submission.append([pair[0] + '-' + pair[1], str(result['prediction'])])\n",
    "filename = \"submission.csv\"\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerows(submission)\n",
    "print(f\"Saved '{filename}'\")\n",
    "\n",
    "import pandas\n",
    "print('Loading ' + filename)\n",
    "submission_df = pandas.read_csv(filename, delimiter=',', header='infer')\n",
    "submission_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
